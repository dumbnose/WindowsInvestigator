# DP SLI Investigation Workflow

**When to use:** For investigating Service Level Indicator (SLI) drops, service degradation incidents, and proactive monitoring of service health.

This workflow provides a systematic approach for Log Search Alerts SLI investigation that integrates global monitoring with detailed root cause analysis.

## ğŸ¯ Workflow Overview

This workflow provides a systematic approach to:

- ğŸ” Run global SLI investigation to detect drops under 99.9%
- ğŸ“Š Stop if no drops are found globally
- ğŸŒ Identify relevant regions when drops are detected
- ğŸ‘¥ Calculate impact by subscription and rule ID
- ğŸ“‹ Create investigation table for further analysis
- ğŸ”§ Run investigation for each table row using the DRI-agent for root cause analysis with dependencies and exceptions tables

### Example User Requests
```
/dp-sli-investigation-workflow.md from 2025-08-31 to 2025-09-07
```

## ğŸ“‹ Workflow Steps

### Step 1: Global SLI Investigation

**Process:** Run global SLI investigation using Log Search Alerts process

**ğŸš¨ CRITICAL REQUIREMENTS:**

- **ğŸ“Š Data Binning**: Always bin the data by 1h maximum for temporal analysis
- **ğŸ“ˆ Trend Analysis**: Look at the trend and check for drops under 99.9% per 1h
- **ğŸ›‘ Stop Condition**: If no drops under 99.9% are found, stop investigation here

**Prerequisites:**

- Read and use `memory-bank/sli-investigation.md`
- Connect to cluster: `azalertsprodweu.westeurope.kusto.windows.net`
- Database: `LogAlertsScheduler`

**Step 1a: Execute Global SLI Health Check with 1h Binning**

```kql
LogAlertsSchedulerSliLogs 
| where MetricName == "RuleEvaluationSuccessRate" 
| where TIMESTAMP between(datetime(YYYY-MM-DD) .. datetime(YYYY-MM-DD)) 
| extend ExcludeFromSli = tostring(MetricInfo.Dimensions.ExcludeFromSli),
         MonitoringSystem = tostring(MetricInfo.Dimensions.MonitoringSystem),
         AlertCondition = tostring(MetricInfo.Dimensions.AlertCondition),
         Success = tostring(MetricInfo.Dimensions.Success) 
| where ExcludeFromSli == "False" 
| where MonitoringSystem == "Log Search Alerts" 
| where AlertCondition == "Fired" 
| summarize Expected = count(), Completed = countif(Success == "True") by bin(TIMESTAMP, 1h)  // ğŸš¨ CRITICAL: 1h binning required
| project TIMESTAMP, Expected, Completed, SuccessRate = round((todouble(Completed)*100.0)/todouble(Expected), 3) 
| extend SliStatus = case(
    SuccessRate >= 99.9, "âœ… HEALTHY",
    SuccessRate >= 99.5, "âš ï¸ DEGRADED", 
    SuccessRate >= 99.0, "ğŸ”´ CRITICAL",
    "ğŸš¨ EMERGENCY"
)
| order by TIMESTAMP asc
```

**Step 1b: Trend Analysis - Check for Drops Under 99.9%**

- **ğŸ¯ Primary Focus**: Look at trend and identify any periods where `SuccessRate < 99.9`
- **ğŸ“Š Temporal Pattern**: Analyze hourly trend to identify degradation patterns
- **ğŸ›‘ Decision Point**:
  - **âœ… No drops under 99.9%**: Investigation complete - service is healthy, **STOP HERE**
  - **ğŸ”´ Drops detected**: Continue with regional and impact analysis

**Step 1c: SLI Drop Detection Query**

```kql
LogAlertsSchedulerSliLogs 
| where MetricName == "RuleEvaluationSuccessRate" 
| where TIMESTAMP between(datetime(YYYY-MM-DD) .. datetime(YYYY-MM-DD)) 
| extend ExcludeFromSli = tostring(MetricInfo.Dimensions.ExcludeFromSli),
         MonitoringSystem = tostring(MetricInfo.Dimensions.MonitoringSystem),
         AlertCondition = tostring(MetricInfo.Dimensions.AlertCondition),
         Success = tostring(MetricInfo.Dimensions.Success) 
| where ExcludeFromSli == "False" 
| where MonitoringSystem == "Log Search Alerts" 
| where AlertCondition == "Fired" 
| summarize Expected = count(), Completed = countif(Success == "True") by bin(TIMESTAMP, 1h)
| project TIMESTAMP, Expected, Completed, SuccessRate = round((todouble(Completed)*100.0)/todouble(Expected), 3) 
| extend SliStatus = case(
    SuccessRate >= 99.9, "âœ… HEALTHY",
    SuccessRate >= 99.5, "âš ï¸ DEGRADED", 
    SuccessRate >= 99.0, "ğŸ”´ CRITICAL",
    "ğŸš¨ EMERGENCY"
)
| where SuccessRate < 99.9  // ğŸš¨ Only show drops under 99.9%
| order by TIMESTAMP asc
```

**Decision Point:**

- **âœ… No drops under 99.9%**: Investigation complete - service is healthy
- **ğŸ”´ Drops detected**: Continue with Step 2 for regional and impact analysis

### Step 2: Regional Impact and Customer Analysis (Only if drops detected)

**Process:** Identify relevant regions and calculate detailed impact metrics

**Step 2a: Regional Impact Analysis**

```kql
LogAlertsSchedulerSliLogs 
| where MetricName == "RuleEvaluationSuccessRate" 
| where TIMESTAMP between(datetime(YYYY-MM-DD) .. datetime(YYYY-MM-DD)) 
| extend ExcludeFromSli = tostring(MetricInfo.Dimensions.ExcludeFromSli),
         MonitoringSystem = tostring(MetricInfo.Dimensions.MonitoringSystem),
         AlertCondition = tostring(MetricInfo.Dimensions.AlertCondition),
         Success = tostring(MetricInfo.Dimensions.Success),
         Location = tostring(MetricInfo.Dimensions.MonitoringSystemLocation)
| where ExcludeFromSli == "False" 
| where MonitoringSystem == "Log Search Alerts" 
| where AlertCondition == "Fired" 
| summarize Expected = count(), Completed = countif(Success == "True") by Location, bin(TIMESTAMP, 1h) 
| project TIMESTAMP, Location, Expected, Completed, SuccessRate = round((todouble(Completed)*100.0)/todouble(Expected), 3)
| extend SliStatus = case(
    SuccessRate >= 99.9, "âœ… HEALTHY",
    SuccessRate >= 99.5, "âš ï¸ DEGRADED", 
    SuccessRate >= 99.0, "ğŸ”´ CRITICAL",
    "ğŸš¨ EMERGENCY"
)
| where SuccessRate < 99.9
| order by TIMESTAMP asc, Location
```

**Step 2b: Subscription and Rule Impact Analysis**

```kql
LogAlertsSchedulerSliLogs 
| where MetricName == "RuleEvaluationSuccessRate" 
| where TIMESTAMP between(datetime(YYYY-MM-DD) .. datetime(YYYY-MM-DD)) 
| extend ExcludeFromSli = tostring(MetricInfo.Dimensions.ExcludeFromSli),
         MonitoringSystem = tostring(MetricInfo.Dimensions.MonitoringSystem),
         AlertCondition = tostring(MetricInfo.Dimensions.AlertCondition),
         Success = tostring(MetricInfo.Dimensions.Success),
         SubscriptionId = tostring(MetricInfo.Dimensions.SubscriptionId),
         RuleId = tostring(MetricInfo.Dimensions.RuleId),
         Location = tostring(MetricInfo.Dimensions.MonitoringSystemLocation)
| where ExcludeFromSli == "False" 
| where MonitoringSystem == "Log Search Alerts" 
| where AlertCondition == "Fired" 
| where Success == "False"
| where isnotempty(SubscriptionId) and isnotempty(RuleId)
| summarize 
    FailedEvaluations = count(),
    DistinctImpactedSubscriptions = dcount(SubscriptionId),
    DistinctImpactedRules = dcount(RuleId),
    SampleFailedRules = make_set(RuleId, 10),
    AffectedRegions = make_set(Location)
by bin(TIMESTAMP, 1h)
| project TIMESTAMP, FailedEvaluations, DistinctImpactedSubscriptions, DistinctImpactedRules, SampleFailedRules, AffectedRegions
| order by TIMESTAMP asc
```

### Step 3: Investigation Priority Table Creation

**Process:** Create prioritized table of issues requiring further investigation

**Step 3a: Generate Investigation Priority Matrix**

Create a table with the following structure for each detected drop:

| ğŸ• Time Period | ğŸŒ Region | ğŸ“Š Success Rate | ğŸš¨ Severity | ğŸ‘¥ Subscription Impact | ğŸ“‹ Rule Impact | ğŸ” Investigation Priority |
|----------------|-----------|-----------------|-------------|------------------------|----------------|---------------------------|
| YYYY-MM-DD HH:00 | Region Name | XX.X% | Critical/Emergency | X subscriptions | X rules | High/Medium/Low |

**Step 3b: Prioritization Criteria**

- **ğŸ”´ High Priority**: Success rate < 99.0%, >100 impacted subscriptions, >500 impacted rules
- **ğŸŸ¡ Medium Priority**: Success rate 99.0-99.4%, 50-100 impacted subscriptions, 100-500 impacted rules  
- **ğŸŸ¢ Low Priority**: Success rate 99.5-99.8%, <50 impacted subscriptions, <100 impacted rules

**Step 3c: Investigation Scope Definition**
For each priority item, define:

- Target time window for root cause analysis
- Specific regions to investigate
- Expected investigation depth (dependencies + exceptions vs exceptions only)

### Step 4: DRI-Agent Root Cause Investigation

**Process:** For each priority issue from Step 3, conduct detailed root cause analysis using DRI-agent methodology

**Prerequisites:**

1. **Read DRI-Agent Documentation**: Follow instructions in `.clinerules/04-livesite-investigation-process.md`
2. **Read Investigation Methodology**: Review `.clinerules/subagents/dri-agent/investigation-methodology.md` for systematic approach
3. **Connect to LogAlertsScheduler Database**: Use appropriate Kusto cluster for LSA telemetry

**Step 4a: Setup Investigation Documentation**
Create investigation file for each priority issue:

```
Naming convention: sli-investigation-{start-date}_{end-date}_{region}-root-cause.md
Example: sli-investigation-2025-06-11_2025-06-11_japaneast-root-cause.md
```

**Step 4b: Dependencies Analysis (lsa_dependencies table)**
**Process:** Investigate external service failures for each affected region and time period

**CRITICAL: Use the FULL incident timeframe identified in Steps 1-2**

```kql
// Dependencies analysis for specific region and timeframe
lsa_dependencies
| where timestamp between(datetime({incident_start}) .. datetime({incident_end}))
| extend Location = tostring(customDimensions.Location)
| where Location == "{target_region}"  // From Step 2 regional analysis
| where success == "False"
| summarize 
    FailureCount = count(),
    TotalRequests = count(),
    FailureRate = round(countif(success == "False") * 100.0 / count(), 2),
    SampleTargets = make_set(name, 5),
    SampleData = make_set(data, 3)
by bin(timestamp, 15m)
| where FailureCount > 0
| order by timestamp asc, FailureCount desc
```

**Common LSA Dependency Patterns to Check:**

- **Draft API Issues**: Look for "Draft" in name or data fields
- **Azure Storage Issues**: Table Storage, Queue Storage timeouts or throttling
- **Kusto/LogAnalytics**: Query execution failures or timeouts  
- **HTTP Services**: Any HTTP dependency failures
- **Authentication Issues**: AAD token acquisition failures

**Step 4c: Exceptions Analysis (lsa_exceptions table)**
**Process:** Analyze application exceptions that correlate with SLI drops

```kql
// Exceptions analysis for specific region and timeframe
lsa_exceptions
| where timestamp between(datetime({incident_start}) .. datetime({incident_end}))
| extend Location = tostring(customDimensions.Location)
| where Location == "{target_region}"  // From Step 2 regional analysis
| where outerType has_any("Draft", "Http", "Storage", "Timeout", "Internal", "Server") 
   or outerMessage has_any("Draft", "Http", "Storage", "Timeout", "Internal", "Server")
| extend ExceptionCategory = case(
    outerType contains "Draft", "Draft_API",
    outerType contains "HttpInternalServerError", "HTTP_500",
    outerType contains "TimeoutException", "Timeout",
    outerType contains "StorageException", "Storage",
    "Other"
)
| summarize 
    ExceptionCount = count(),
    UniqueTypes = dcount(outerType),
    SampleTypes = make_set(outerType, 5),
    SampleMessages = make_set(outerMessage, 3)
by ExceptionCategory, bin(timestamp, 15m)
| where ExceptionCount > 0
| order by timestamp asc, ExceptionCount desc
```

**Critical LSA Exception Patterns:**

- **DraftHttpInternalServerErrorException**: Draft service failures
- **HTTP 500 Errors**: Internal server errors
- **Timeout Exceptions**: Service timeout issues
- **Storage Exceptions**: Azure Storage connectivity issues

**Step 4d: Root Cause Hypothesis Formation**
**Process:** Apply critical thinking framework from investigation methodology

**Validation Requirements:**

- **Temporal Correlation**: Does the suspected cause align with SLI drop timeline?
- **Regional Distribution**: Is the pattern consistent across affected regions?
- **Evidence Strength**: Multiple independent sources support the hypothesis?
- **Alternative Explanations**: Have other possible causes been ruled out?

**Step 4e: Cross-Regional Pattern Analysis**
Compare dependency and exception patterns across all affected regions to identify:

- Global vs regional issues
- Failure propagation patterns
- Regional infrastructure correlations
- Recovery pattern differences

**Step 4f: Documentation Requirements**
Document in each regional investigation file:

- SLI drop timeline and severity
- Dependency failure patterns and affected services
- Exception analysis with categorized error types
- Root cause hypothesis with supporting evidence
- Recovery timeline and restoration patterns

### Step 5: Consolidated Investigation Report

**Process:** Generate comprehensive report consolidating all findings from Steps 1-4

**Step 5a: Report Structure**
Create final investigation report with:

- Executive summary of global SLI health
- Timeline of all detected drops under 99.9%
- Regional impact breakdown
- Subscription and rule impact analysis
- Root cause analysis for each priority issue
- Remediation recommendations

**Step 5b: Root Cause Integration**
For each investigated drop from Step 4:

- Integrate dependency failure findings
- Include exception analysis results
- Present consolidated root cause hypothesis
- Provide specific remediation steps

**Step 5c: Cross-Issue Pattern Analysis**
Identify patterns across multiple drops:

- Common dependency failures across regions
- Similar exception patterns
- Global vs regional root causes
- Service-wide vs localized issues

### Step 6: Investigation Report Generation and Chat Output

**Process:** Generate comprehensive SLI investigation report with detailed tables and customer impact analysis

**Step 6a: Chat Output Generation Structure**

**Present the complete SLI analysis directly in the Cline chat using the following structure:**

## ğŸ” SLI Investigation Report

- **ğŸ• Investigation Time:** [current_timestamp]
- **ğŸ“… Time Range:** [analyzed_time_range]  
- **ğŸ”§ Cluster:** azalertsprodweu.westeurope.kusto.windows.net
- **ğŸ—„ï¸ Database:** LogAlertsScheduler
- **ğŸ¥ Overall SLI Health Status:** [health_status_summary]
- **ğŸš¨ Critical Issues:** [critical_issue_count]

## ğŸ“‹ Executive Summary

- **ğŸ“Š Total Rule Evaluations:** [total_evaluation_count]
- **âœ… Overall Success Rate:** [overall_success_rate]%
- **âŒ Failed Evaluations:** [total_failed_evaluations]
- **â° Peak Failure Time:** [peak_failure_time]
- **ğŸŒ Most Affected Region:** [worst_performing_region]
- **ğŸ“ˆ Recovery Status:** [current_recovery_status]

## ğŸ• SLI Drop Timeline Analysis (Hourly Granularity)

| ğŸ• Time Period | ğŸ“Š Expected | âœ… Completed | ğŸ“ˆ Success Rate | ğŸš¦ Status | âŒ Failed Evaluations | ğŸŒ Affected Regions |
|----------------|-------------|--------------|-----------------|-----------|---------------------|-------------------|
| [timestamp] | [expected] | [completed] | [rate]% | [status_emoji] | [failures] | [region_count] |

## ğŸŒ Regional Impact Analysis (Only Drops Under 99.9%)

| ğŸ• Time Period | ğŸŒ Region | ğŸ“Š Expected | âœ… Completed | ğŸ“ˆ Success Rate | ğŸš¦ SLI Status | âŒ Failures |
|----------------|-----------|-------------|--------------|-----------------|---------------|-------------|
| [timestamp] | [location] | [expected] | [completed] | [rate]% | [status_emoji] | [failures] |

## ğŸ‘¥ Customer Impact Analysis (Failed Evaluations Only)

| ğŸ• Time Period | âŒ Failed Evaluations | ğŸ¢ Impacted Subscriptions | ğŸ“‹ Impacted Rules | ğŸ“Š Sample Failed Rules |
|----------------|----------------------|---------------------------|-------------------|------------------------|
| [timestamp] | [failures] | [subscription_count] | [rule_count] | [sample_rules] |

## ğŸ¢ Overall Impact Summary by Region

| ğŸŒ Region | ğŸ“Š Total Evaluations | âŒ Failed Evaluations | ğŸ“ˆ Success Rate | ğŸ¢ Total Subscriptions | ğŸ‘¥ Impacted Subscriptions | ğŸ“Š Subscription Impact % | ğŸ“‹ Total Rules | âŒ Impacted Rules | ğŸ“Š Rule Impact % |
|-----------|---------------------|----------------------|-----------------|------------------------|---------------------------|-------------------------|-------------|-------------------|-------------------|
| [location] | [total] | [failed] | [rate]% | [total_subs] | [impacted_subs] | [sub_impact]% | [total_rules] | [impacted_rules] | [rule_impact]% |

## ğŸ” Top Impacted Subscriptions Analysis

| ğŸ¢ Subscription ID | ğŸ“Š Total Evaluations | âŒ Failed Evaluations | ğŸ“‹ Rules in Subscription | ğŸ“Š Failure Rate % |
|-------------------|---------------------|----------------------|--------------------------|-------------------|
| [subscription_id] | [total] | [failed] | [rule_count] | [failure_rate]% |

## ğŸ”„ Service Recovery Pattern Analysis

| ğŸ• Time Period | ğŸŒ Region | ğŸ“Š Expected | âœ… Completed | ğŸ“ˆ Success Rate | ğŸ”„ Recovery Status |
|----------------|-----------|-------------|--------------|-----------------|-------------------|
| [timestamp] | [location] | [expected] | [completed] | [rate]% | [recovery_emoji] |

**Recovery Status Legend:**

- âœ… **RECOVERED**: â‰¥99.9% success rate
- ğŸ”„ **RECOVERING**: 99.5-99.8% success rate  
- ğŸ”„ **SLOW_RECOVERY**: 99.0-99.4% success rate
- ğŸ”´ **DEGRADED**: 95.0-98.9% success rate
- ğŸš¨ **CRITICAL**: <95.0% success rate

## ğŸ”§ Root Cause Analysis (Regional Dependency & Exception Investigation)

### ğŸ” Primary Findings from DRI-Agent Investigation

| ğŸ”§ Root Cause Category | ğŸŒ Affected Regions | ğŸ“Š Failure Count | ğŸ• Timeline | ğŸ”— Evidence |
|------------------------|-------------------|------------------|-------------|-------------|
| [cause_category] | [regions] | [failure_count] | [timeframe] | [evidence_summary] |

### ğŸ”— Dependency Analysis Results

| ğŸ› ï¸ Service Category | ğŸ• Failure Timeline | âŒ Failure Count | ğŸ”„ Failure Rate % | ğŸ“‹ Sample Messages |
|---------------------|---------------------|------------------|-------------------|-------------------|
| [service_type] | [timestamp] | [count] | [rate]% | [messages] |

### âš ï¸ Exception Analysis Results  

| ğŸ”¥ Exception Category | ğŸ• Timeline | ğŸ“Š Count | ğŸ”§ Unique Types | ğŸ“‹ Sample Types | ğŸ’¬ Sample Messages |
|----------------------|-------------|----------|------------------|------------------|-------------------|
| [exception_type] | [timestamp] | [count] | [unique_count] | [types] | [messages] |

### ğŸŒ Cross-Regional Comparison

| ğŸŒ Region | ğŸ• Peak Failure Time | ğŸ”— Dependency Failures | âš ï¸ Exception Count | ğŸ”§ Top Failing Services |
|-----------|---------------------|------------------------|-------------------|------------------------|
| [location] | [timestamp] | [dep_failures] | [exception_count] | [services] |

## ğŸ‘¥ Customer Impact Assessment

- **ğŸ“Š Peak Failure Rate:** [peak_failure_rate]% at [peak_time]
- **âŒ Total Failed Evaluations:** [total_failures] evaluations
- **ğŸŒ Regional Impact:** [affected_regions]
- **ğŸ¢ Subscription Impact:** [subscription_impact_summary]
- **ğŸ“‹ Alert Rule Impact:** [rule_impact_summary]
- **â±ï¸ Total Degradation Duration:** [degradation_duration]
- **ğŸ”„ Recovery Duration:** [recovery_duration]

## ğŸš¨ Immediate Actions Required

1. **ğŸ”´ Priority 1**: [Critical action with timeline]
2. **ğŸŸ¡ Priority 2**: [Important action with responsible team]  
3. **ğŸŸ¢ Priority 3**: [Monitoring action with specific metrics]

## ğŸ’¡ Recommendations

### ğŸ”§ Short-term Actions

- **ğŸ› ï¸ Immediate**: [Immediate remediation steps]
- **ğŸ“Š Monitoring**: [Monitoring improvements]
- **ğŸš¨ Alerting**: [Alert threshold adjustments]

### ğŸ“ˆ Long-term Improvements  

- **ğŸ”§ Reliability**: [Service reliability enhancements]
- **âš¡ Performance**: [Performance optimization opportunities]
- **ğŸ“Š Monitoring**: [Monitoring and alerting improvements]

## ğŸ“š Additional Resources

- **ğŸ”§ Kusto Cluster**: [azalertsprodweu.westeurope.kusto.windows.net](https://azalertsprodweu.westeurope.kusto.windows.net)
- **ğŸ“„ Investigation Documentation**: [investigation_file_path]
- **ğŸ“Š Related Dashboards**: [monitoring_dashboard_links]
- **â˜ï¸ Escalation Contacts**: [team_contact_information]

**ğŸ“‹ Chat Delivery Guidelines:**

- Present the entire analysis in a single, well-formatted chat response
- Use markdown formatting for headers, tables, and lists with extensive emoji usage
- Include specific metrics and percentages in all summaries
- Ensure tables are properly formatted for chat display with emoji headers
- Break up long sections with appropriate emoji headers
- Always conclude with actionable next steps
- Include specific Kusto queries used if user requests them
- Provide clear status indicators (âœ…ğŸŸ¡ğŸŸ ğŸ”´ğŸ’€ğŸš¨ğŸ”„) throughout all tables

### Step 5: Integration with Root Cause Analysis

**Process:** Consolidate regional findings into comprehensive analysis

**Integration Steps:**

- ğŸ”„ Synthesize findings from all regional investigations
- ğŸ¯ Identify primary root cause and contributing factors  
- ğŸ“… Correlate with deployment timelines and infrastructure changes
- ğŸ“Š Document comprehensive timeline and customer impact assessment
- ğŸ’¡ Provide recommendations for prevention and monitoring improvements

## ğŸ”§ Technical Requirements

### Prerequisites

- Access to appropriate Kusto cluster for the service being investigated
- AAD authentication for service-specific databases
- Understanding of KQL query syntax
- Familiarity with time binning and sampling strategies

### Key Tools and Techniques

- **Primary Data Source**: Service-specific SLI data table (defined in memory-bank process)
- **Query Language**: KQL (Kusto Query Language)
- **Time Binning**: 1h for short periods, 1h for longer investigations
- **Sampling**: Use `sample N` for large datasets to prevent timeouts
- **Filtering**: Focus on service-specific data as defined in memory-bank process

## âš ï¸ Important Considerations

### ğŸš¨ Critical Investigation Mistakes to Avoid

**Based on lessons learned from failed investigations:**

| âŒ **Common Mistake** | âœ… **Correct Approach** | ğŸ¯ **Impact** |
|----------------------|-------------------------|--------------|
| **â° Time Window Limitations** | Use FULL incident timeframe (08:00-13:00 UTC) | Avoids missing critical failure patterns |
| **ğŸ” Insufficient Search Patterns** | Use broad patterns with `has_any()` and `contains` | Captures all service failures ("Draft", "Http", "Storage") |  
| **ğŸ”š Premature Conclusions** | Try multiple search approaches across different tables | Prevents "no failures found" false conclusions |
| **ğŸŒ Single Region Focus** | Compare patterns across ALL affected regions | Identifies global vs regional issues |
| **ğŸ”§ Missing Service-Specific Issues** | Search for specific patterns like "DraftHttpInternalServerErrorException" | Captures service-specific failure modes |

### ğŸ“Š Investigation Quality Checklist

| âœ… **Validation Step** | ğŸ“‹ **Requirement** | ğŸ¯ **Purpose** |
|------------------------|-------------------|----------------|
| **â° Full Timeframe** | Used full incident timeframe, not just peak periods | Complete failure pattern analysis |
| **ğŸ” Service Patterns** | Searched for Draft, Http, Storage, etc. patterns | Service-specific failure detection |  
| **ğŸŒ Regional Coverage** | Examined all affected regions, not just worst-affected | Global vs regional issue identification |
| **ğŸ”§ Search Breadth** | Used broad search patterns with `has_any()` and `contains` | Comprehensive failure discovery |
| **ğŸ”— Cross-Reference** | Cross-referenced findings between dependencies and exceptions | Root cause validation |
| **ğŸ“Š Multi-Source** | Validated findings against multiple telemetry sources | Evidence strength confirmation |

### Query Performance

- **Large datasets**: Use sampling and appropriate time binning
- **Timeout prevention**: Break large date ranges into smaller chunks
- **Progressive investigation**: Start broad, then drill down to specific periods

### Data Interpretation

- **Success rate threshold**: 99.9% is the standard SLI threshold
- **Service baseline**: Normal operation is typically 99.95%+ success rate
- **Processing volume**: 20-22 million evaluations per hour during peak times
- **Time zones**: All timestamps are in UTC

### Investigation Scope

- **Focus on degradation**: Only investigate periods below 99.9% success rate
- **Document everything**: Record all findings for future reference
- **Regional analysis**: Consider geographical distribution of issues
- **Recovery patterns**: Note how the service returned to normal operation

### ğŸ“‹ Investigation Validation Checklist

| âœ… **Validation Check** | ğŸ“Š **Verification Method** | ğŸ¯ **Success Criteria** |
|------------------------|---------------------------|------------------------|
| **â° Full Timeframe Usage** | Review query time ranges | All queries use complete incident window |
| **ğŸ” Service Pattern Search** | Check for Draft, Http, Storage patterns | Broad service-specific search executed |
| **ğŸŒ Regional Coverage** | Verify all affected regions analyzed | Complete regional comparison performed |
| **ğŸ”§ Search Pattern Breadth** | Confirm `has_any()` and `contains` usage | Comprehensive failure pattern discovery |
| **ğŸ”— Cross-Reference Analysis** | Dependencies vs exceptions correlation | Root cause hypothesis supported by multiple sources |
| **ğŸ“Š Multi-Source Validation** | Multiple telemetry table analysis | Consistent findings across different data sources |

## ğŸ“ˆ Success Criteria

| ğŸ¯ **Success Metric** | ğŸ“Š **Deliverable** | âœ… **Quality Standard** |
|----------------------|-------------------|------------------------|
| **ğŸ• Clear Timeline** | Degradation occurrence and resolution timeline | Hourly granularity with precise start/end times |
| **ğŸ“Š Quantified Impact** | Failure counts, success rates, customer impact | Specific numbers with subscription and rule impact |
| **â±ï¸ Duration Analysis** | Issue persistence timeframe | Complete degradation and recovery duration |
| **ğŸŒ Regional Scope** | Geographical impact understanding | All affected regions analyzed with comparison |
| **ğŸ”„ Recovery Assessment** | Service restoration pattern analysis | Recovery progression with status transitions |
| **ğŸ”§ Root Cause Evidence** | Dependency and exception analysis | Multi-source evidence supporting hypothesis |
| **ğŸ‘¥ Customer Impact** | Subscription and alert rule impact quantification | Specific customer impact metrics and percentages |

## ğŸ”— Related Processes

This workflow integrates with:

- **Live Site Investigation** (`.clinerules/04-livesite-investigation-process.md`) for detailed root cause analysis
- **General Investigation Methodology** (`.clinerules/subagents/dri-agent/investigation-methodology.md`) for systematic troubleshooting
- **Telemetry Analysis** (`memory-bank/telemetry.md`) for detailed error investigation

---

*This workflow should be the first step in any service degradation investigation, providing the foundation for deeper analysis and root cause identification.*
